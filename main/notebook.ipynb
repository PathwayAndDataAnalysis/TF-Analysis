{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1. One Solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 10_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        # Create a new df\n",
    "        df = np.array([sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]) for x in\n",
    "                       up_down_tuple_list])\n",
    "\n",
    "        # Create a new column reverse_rank in df and store reverse rank sum\n",
    "        rev_df = np.array([sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]]) for x in\n",
    "                           up_down_tuple_list])\n",
    "\n",
    "        # Find the minimum between df and rev_df\n",
    "        min_df = np.minimum(df, rev_df)\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv'  # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    # main(priors_file, diff_file)\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 10):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T12:31:55.787580Z",
     "end_time": "2023-04-12T12:33:13.446569Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Very similar the previous solution, Only difference is that I used single loop to find min rank sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.027778893010691, 1.8819898220244795, 1.8718398108612746, 1.8752486209850758, 1.8878434840589762]\n",
      "Average Time:  1.9089401261880994\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 2_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        min_df = np.array(\n",
    "            [\n",
    "                min(\n",
    "                    sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                    sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "                )\n",
    "                for x in up_down_tuple_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 5):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:17:25.974739Z",
     "end_time": "2023-04-25T09:17:35.532933Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Testing solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.137474172981456, 2.1173193268477917, 2.1170656660106033, 2.0967027300503105, 2.119473071070388]\n",
      "Average Time:  2.11760699339211\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 2_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        min_df = np.array(\n",
    "            [\n",
    "                min([\n",
    "                    # sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                    np.sum(np.concatenate((randomly_drawn_list[:x[0]], reverse_randomly_drawn_list[x[0]:x[0] + x[1]]))),\n",
    "                    # sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "                    np.sum(np.concatenate((reverse_randomly_drawn_list[:x[0]], randomly_drawn_list[x[0]:x[0] + x[1]])))\n",
    "                ])\n",
    "                for x in up_down_tuple_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 5):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:15:51.281915Z",
     "end_time": "2023-04-25T09:16:02.075310Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bb = np.zeros((2, 3))\n",
    "\n",
    "print(bb[1, 2])\n",
    "\n",
    "aa = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(np.min(aa))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:13:28.312220Z",
     "end_time": "2023-04-18T15:13:28.312414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array([350])\n",
    "b = np.array([110, 100])\n",
    "\n",
    "# Sum all elements of a and b\n",
    "print(np.sum(np.concatenate((a, b))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:19:27.256051Z",
     "end_time": "2023-04-18T15:19:27.282180Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparisons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Min between positive and negative view"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  27.07565044402145\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 100_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        # randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "        randomly_drawn_list = np.random.choice(max_rank + 1, max_targets, replace=False)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        min_df = np.array(\n",
    "            [\n",
    "                min(\n",
    "                    sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                    sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "                )\n",
    "                for x in up_down_tuple_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    start = timer()\n",
    "    main(priors_file, diff_file)\n",
    "    end = timer()\n",
    "    print(\"Time taken: \", end - start)\n",
    "\n",
    "    # times_takes = []\n",
    "    # for i in range(0, 5):\n",
    "    #     start = timer()\n",
    "    #     main(priors_file, diff_file)\n",
    "    #     end = timer()\n",
    "    #     times_takes.append(end - start)\n",
    "    #\n",
    "    # print(times_takes)\n",
    "    # print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T13:17:34.691725Z",
     "end_time": "2023-04-25T13:17:34.692048Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Only Positive View"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  25.7131263660267\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "    updown_df2 = updown_df.copy()\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 50_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "    results_array2 = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.choice(max_rank + 1, max_targets, replace=False)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        results_array[:, i] = [\n",
    "            min(\n",
    "                sum(randomly_drawn_list[:x[0] + x[1]]),\n",
    "                sum(reverse_randomly_drawn_list[:x[0] + x[1]])\n",
    "            )\n",
    "            for x in up_down_tuple_list\n",
    "        ]\n",
    "        results_array2[:, i] = [\n",
    "            min(\n",
    "                sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "            )\n",
    "            for x in up_down_tuple_list\n",
    "        ]\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "    updown_df2 = pd.concat([updown_df2, pd.DataFrame(results_array2)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    rank_sum_df2 = updown_df2[['up_down_tuple']].copy()\n",
    "    rank_sum_df2['rank_sum_list2'] = updown_df2.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "    target_counts_df['rank_sum_list2'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df2[rank_sum_df2['up_down_tuple'] == x]['rank_sum_list2'].values[0])\n",
    "\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    target_counts_df['rank_sum_less_than_actual2'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list2'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "    target_counts_df['p-value2'] = target_counts_df['rank_sum_less_than_actual2'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "    target_counts_df.drop(['rank_sum_list2'], axis=1, inplace=True)\n",
    "    target_counts_df.drop(['rank_sum_less_than_actual2'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file_new.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    start = timer()\n",
    "    main(priors_file, diff_file)\n",
    "    end = timer()\n",
    "    print(\"Time taken: \", end - start)\n",
    "\n",
    "    # times_takes = []\n",
    "    # for i in range(0, 5):\n",
    "    #     start = timer()\n",
    "    #     main(priors_file, diff_file)\n",
    "    #     end = timer()\n",
    "    #     times_takes.append(end - start)\n",
    "    #\n",
    "    # print(times_takes)\n",
    "    # print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:14:20.266901Z",
     "end_time": "2023-04-25T16:14:46.040056Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "  Symbols                   count  actual_min_rank_sum  IsPosNeg  \\\n1      AR             [1, -1, -1]                  304  Negative   \n2    ARNT        [1, 1, 1, 1, -1]                 1015  Negative   \n3    ATF2      [1, 1, 1, 1, 1, 1]                 1177  Negative   \n4    ATF4  [1, 1, 1, 1, 1, 1, -1]                  798  Positive   \n5    BCL6             [1, -1, -1]                  152  Negative   \n\n  up_down_tuple  rank_sum_less_than_actual  p-value  p-value2  \n1        (1, 2)                       6599  0.13198   0.13376  \n2        (4, 1)                      47117  0.94234   0.94106  \n3        (6, 0)                      41434  0.82868   0.82868  \n4        (6, 1)                       1788  0.03576   0.03904  \n5        (1, 2)                        837  0.01674   0.01586  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbols</th>\n      <th>count</th>\n      <th>actual_min_rank_sum</th>\n      <th>IsPosNeg</th>\n      <th>up_down_tuple</th>\n      <th>rank_sum_less_than_actual</th>\n      <th>p-value</th>\n      <th>p-value2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>AR</td>\n      <td>[1, -1, -1]</td>\n      <td>304</td>\n      <td>Negative</td>\n      <td>(1, 2)</td>\n      <td>6599</td>\n      <td>0.13198</td>\n      <td>0.13376</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ARNT</td>\n      <td>[1, 1, 1, 1, -1]</td>\n      <td>1015</td>\n      <td>Negative</td>\n      <td>(4, 1)</td>\n      <td>47117</td>\n      <td>0.94234</td>\n      <td>0.94106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ATF2</td>\n      <td>[1, 1, 1, 1, 1, 1]</td>\n      <td>1177</td>\n      <td>Negative</td>\n      <td>(6, 0)</td>\n      <td>41434</td>\n      <td>0.82868</td>\n      <td>0.82868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATF4</td>\n      <td>[1, 1, 1, 1, 1, 1, -1]</td>\n      <td>798</td>\n      <td>Positive</td>\n      <td>(6, 1)</td>\n      <td>1788</td>\n      <td>0.03576</td>\n      <td>0.03904</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>BCL6</td>\n      <td>[1, -1, -1]</td>\n      <td>152</td>\n      <td>Negative</td>\n      <td>(1, 2)</td>\n      <td>837</td>\n      <td>0.01674</td>\n      <td>0.01586</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read file\n",
    "pos_neg = pd.read_csv('../output/output_file_new.csv')\n",
    "# Delete first row\n",
    "pos_neg = pos_neg.drop([0], axis=0)\n",
    "\n",
    "pos_neg.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:14:49.532080Z",
     "end_time": "2023-04-25T16:14:49.554618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_neg['p-value'] = pos_neg['p-value'].astype(float)\n",
    "pos_neg['p-value2'] = pos_neg['p-value2'].astype(float)\n",
    "\n",
    "# sort dataframe by p-value\n",
    "pos_neg = pos_neg.sort_values(by=['p-value'], ascending=True, ignore_index=True)\n",
    "\n",
    "plt.plot(pos_neg['p-value'], label='p-value')\n",
    "plt.plot(pos_neg['p-value2'], label='p-value2')\n",
    "plt.xlabel('Symbols')\n",
    "plt.ylabel('p-value')\n",
    "plt.title('Comparison of p-value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Export plot as png file\n",
    "plt.savefig('../output/comparison.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:14:52.367386Z",
     "end_time": "2023-04-25T16:14:52.666610Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finalized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 4, 10,  2,  8,  0,  6,  1,  7,  5,  9])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.choice(11, 10, replace=False)\n",
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T16:13:24.949711Z",
     "end_time": "2023-04-25T16:13:24.955039Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
