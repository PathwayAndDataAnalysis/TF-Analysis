{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1. One Solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 10_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        # Create a new df\n",
    "        df = np.array([sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]) for x in\n",
    "                       up_down_tuple_list])\n",
    "\n",
    "        # Create a new column reverse_rank in df and store reverse rank sum\n",
    "        rev_df = np.array([sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]]) for x in\n",
    "                           up_down_tuple_list])\n",
    "\n",
    "        # Find the minimum between df and rev_df\n",
    "        min_df = np.minimum(df, rev_df)\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv'  # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    # main(priors_file, diff_file)\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 10):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T12:31:55.787580Z",
     "end_time": "2023-04-12T12:33:13.446569Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Very similar the previous solution, Only difference is that I used single loop to find min rank sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3236169590090867, 1.6046391249983571, 1.5843852499965578, 1.5816145830031019, 1.591962542006513, 1.5805391669855453, 1.6312808750080876, 1.6042757089890074, 1.6037236669799313, 2.0646612499840558]\n",
      "Average Time:  1.7170699126960245\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 2_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        min_df = np.array(\n",
    "            [\n",
    "                min(\n",
    "                    sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                    sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "                )\n",
    "                for x in up_down_tuple_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 5):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:43:41.515598Z",
     "end_time": "2023-04-18T15:43:58.687664Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Testing solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.652321875008056, 1.9229563330009114, 1.91112004200113, 1.981712791020982, 1.9840418749954551, 2.41145837501972, 1.9952387080120388, 2.1062856249918696, 2.352326499996707, 2.004371250019176]\n",
      "Average Time:  2.1321833374066044\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def get_rank_sum(network: pd.DataFrame, rank_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param network: Causal-priors network in pd.DataFrame format\n",
    "    :param rank_df:  Differential expression data in pd.DataFrame format.\n",
    "    Also contains rank and reverse_rank columns\n",
    "    :return: Actual rank-sum of genes in de dataframe\n",
    "    \"\"\"\n",
    "    # find the maximum number of targets for a Symbol\n",
    "    max_targets = max(network['Symbols'].value_counts().to_dict().values())\n",
    "\n",
    "    # Create a column named is_upregulated in network dataframe, 1 is upregulated and -1 is downregulated\n",
    "    network['is_upregulated'] = np.where(network['action'] == 'upregulates-expression', 1, -1)\n",
    "    # Delete action column from network dataframe\n",
    "    network.drop('action', axis=1, inplace=True)\n",
    "\n",
    "    # Find the positive and negative ranks of targetSymbols\n",
    "    network['rank'] = network['targetSymbol'].apply(lambda x: rank_df[rank_df['Symbols'] == x]['rank'].values[0])\n",
    "    network['reverse_rank'] = network['targetSymbol'].apply(\n",
    "        lambda x: rank_df[rank_df['Symbols'] == x]['reverse_rank'].values[0])\n",
    "\n",
    "    # Calculate the actual rank sum of each Symbol for positive and negative ranks\n",
    "    actual_rank_sum_df = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'reverse_rank'].sum()).reset_index(name='actual_rank_sum')\n",
    "    actual_rank_sum_df['actual_negative_rank_sum'] = network.groupby('Symbols').apply(\n",
    "        lambda x: x[x['is_upregulated'] == 1]['reverse_rank'].sum() + x[x['is_upregulated'] == -1][\n",
    "            'rank'].sum()).reset_index(name='actual_negative_rank_sum')['actual_negative_rank_sum']\n",
    "\n",
    "    # Create a new dataframe with key: Symbols and value: List of 1's and -1's\n",
    "    target_counts_df = network.groupby('Symbols')['is_upregulated'].apply(list).reset_index(name='count')\n",
    "\n",
    "    # Merge actual_rank_sum_df dataframe with target_counts_df dataframe on Symbols column\n",
    "    target_counts_df = pd.merge(target_counts_df, actual_rank_sum_df, on='Symbols')\n",
    "    # Clear actual_rank_sum_df dataframe from memory\n",
    "    del actual_rank_sum_df\n",
    "\n",
    "    # Choose minimum between actual_rank_sum and actual_negative_rank_sum as actual_min_rank_sum\n",
    "    target_counts_df['actual_min_rank_sum'] = target_counts_df.apply(\n",
    "        lambda x: min(x['actual_rank_sum'], x['actual_negative_rank_sum']), axis=1)\n",
    "    # Find which one is minimum and store it in IsPosNeg column\n",
    "    target_counts_df['IsPosNeg'] = target_counts_df.apply(\n",
    "        lambda x: 'Positive' if x['actual_rank_sum'] < x['actual_negative_rank_sum'] else 'Negative',\n",
    "        axis=1)\n",
    "    # Drop actual_rank_sum and actual_negative_rank_sum columns from target_counts_df dataframe\n",
    "    target_counts_df.drop(['actual_rank_sum', 'actual_negative_rank_sum'], axis=1, inplace=True)\n",
    "\n",
    "    # Remove the rows where length of count is less than 3\n",
    "    target_counts_df = target_counts_df[target_counts_df['count'].apply(lambda x: len(x)) >= 3]\n",
    "\n",
    "    # Create a column named up_down_tuple in target_counts_df df, (x, y) x count of 1's and y count of -1's\n",
    "    target_counts_df['up_down_tuple'] = target_counts_df['count'].apply(lambda x: (x.count(1), x.count(-1)))\n",
    "\n",
    "    # Find the max rank from rank_df dataframe\n",
    "    max_rank = rank_df['rank'].max()\n",
    "\n",
    "    # Add a new column in target_counts_df to store how many times the rank sum is less than the actual rank sum\n",
    "    target_counts_df['rank_sum_less_than_actual'] = 0\n",
    "\n",
    "    # Find the unique values in up_down_tuple column and store it in a pandas dataframe\n",
    "    updown_df = pd.DataFrame(target_counts_df['up_down_tuple'].unique(), columns=['up_down_tuple'])\n",
    "\n",
    "    # Convert up_down_tuple into a NumPy array for faster operations\n",
    "    up_down_tuple_list = updown_df['up_down_tuple'].tolist()\n",
    "\n",
    "    rand_iter = 2_000\n",
    "\n",
    "    # Initialize the array to store results\n",
    "    results_array = np.zeros((len(up_down_tuple_list), rand_iter))\n",
    "\n",
    "    for i in range(rand_iter):\n",
    "        # Pick max_targets random numbers from 0 to max_rank+1\n",
    "        randomly_drawn_list = np.random.randint(low=0, high=max_rank + 1, size=max_targets)\n",
    "\n",
    "        # Create reverse randomly_drawn_list from rank_df dataframe\n",
    "        reverse_randomly_drawn_list = max_rank - randomly_drawn_list\n",
    "\n",
    "        min_df = np.array(\n",
    "            [\n",
    "                 min([\n",
    "                    # sum(randomly_drawn_list[:x[0]]) + sum(reverse_randomly_drawn_list[x[0]:x[0] + x[1]]),\n",
    "                    np.sum(np.concatenate((randomly_drawn_list[:x[0]], reverse_randomly_drawn_list[x[0]:x[0] + x[1]]))),\n",
    "                    # sum(reverse_randomly_drawn_list[:x[0]]) + sum(randomly_drawn_list[x[0]:x[0] + x[1]])\n",
    "                    np.sum(np.concatenate((reverse_randomly_drawn_list[:x[0]], randomly_drawn_list[x[0]:x[0] + x[1]])))\n",
    "                 ])\n",
    "                for x in up_down_tuple_list\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the result in the results_array\n",
    "        results_array[:, i] = min_df\n",
    "\n",
    "    # Concatenate updown_df and df and store it in updown_df\n",
    "    updown_df = pd.concat([updown_df, pd.DataFrame(results_array)], axis=1)\n",
    "\n",
    "    # New dataframe using up_down_tuple of updown_df and another column rank_sum_list which contains\n",
    "    # list of rank sums for each up_down_tuple\n",
    "    rank_sum_df = updown_df[['up_down_tuple']].copy()\n",
    "    rank_sum_df['rank_sum_list'] = updown_df.drop('up_down_tuple', axis=1).values.tolist()\n",
    "\n",
    "    # For up_down_tuple in target_counts_df, find the rank_sum_list from rank_sum_df and store it in a new column\n",
    "    target_counts_df['rank_sum_list'] = target_counts_df['up_down_tuple'].apply(\n",
    "        lambda x: rank_sum_df[rank_sum_df['up_down_tuple'] == x]['rank_sum_list'].values[0])\n",
    "\n",
    "    # Count the numbers in rank_sum_list which are less than actual_min_rank_sum and store it in a new column\n",
    "    target_counts_df['rank_sum_less_than_actual'] = target_counts_df.apply(\n",
    "        lambda x: len([i for i in x['rank_sum_list'] if i < x['actual_min_rank_sum']]), axis=1)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    target_counts_df['p-value'] = target_counts_df['rank_sum_less_than_actual'].apply(\n",
    "        lambda x: (x + 1) / rand_iter if x == 0 else x / rand_iter)\n",
    "\n",
    "    # Drop the columns which are not required\n",
    "    target_counts_df.drop(['rank_sum_list'], axis=1, inplace=True)\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    target_counts_df.to_csv('../output/output_file.csv', index=False)\n",
    "\n",
    "\n",
    "def main(cp_file: str, de_file: str):\n",
    "    \"\"\"\n",
    "    :param cp_file: File path of causal-priors file\n",
    "    :param de_file: File path of differential-exp file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cp_file is None or de_file is None:\n",
    "        print('Please provide causal-priors and differential-exp file path')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not isinstance(cp_file, str) or not isinstance(de_file, str):\n",
    "        print('Please provide causal-priors and differential-exp file path as string')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Try except block to handle file not found error\n",
    "    try:\n",
    "        cp = pd.read_csv(cp_file, sep='\\t', header=None)\n",
    "        cp.columns = ['Symbols', 'action', 'targetSymbol', 'reference', 'residual']\n",
    "\n",
    "        # remove all columns except upregulates-expression and downregulates-expression\n",
    "        cp = cp[cp['action'].isin(['upregulates-expression', 'downregulates-expression'])]\n",
    "        # reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # delete reference and residual columns\n",
    "        cp = cp.drop(['reference', 'residual'], axis=1)\n",
    "\n",
    "        de = pd.read_csv(de_file, sep='\\t')\n",
    "\n",
    "        # Create a new column named updown based on positive\n",
    "        # and negative values of SignedP column of de dataframe\n",
    "        de['updown'] = np.where(de['SignedP'] > 0, '1', '-1')\n",
    "\n",
    "        # Sort SignedP column in ascending order if updown column is 1\n",
    "        # and sort absolute values of SignedP column in ascending order if updown column is -1\n",
    "        de = de.sort_values(by=['updown', 'SignedP'], ascending=[False, True])\n",
    "\n",
    "        # Remove rows of cp dataframe if targetSymbol is not present in Symbols column of rank_df dataframe\n",
    "        cp = cp[cp['targetSymbol'].isin(de['Symbols'])]\n",
    "        # Reset index\n",
    "        cp = cp.reset_index(drop=True)\n",
    "\n",
    "        # Add new column named rank to de dataframe\n",
    "        de['rank'] = np.arange(len(de))\n",
    "\n",
    "        # Add reverse_rank column to de dataframe\n",
    "        de['reverse_rank'] = de['rank'].max() - de['rank']\n",
    "\n",
    "        # Sort Symbols column in ascending order of cp dataframe\n",
    "        cp = cp.sort_values(by=['Symbols'], ascending=True, ignore_index=True)\n",
    "\n",
    "        get_rank_sum(cp, de)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', cp_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    priors_file = '../data/causal-priors.txt'\n",
    "    diff_file = '../data/differential-exp.tsv'  # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 415 ranks\n",
    "    # diff_file = '../data/rslp_vs_lum.tsv' # For 50,000 iterations it takes 28 seconds.\n",
    "    # It has 1187 ranks\n",
    "    # diff_file = '../data/basal_vs_lum.tsv' # For 50,000 iterations it takes 14 seconds.\n",
    "    # It has 460 ranks\n",
    "\n",
    "    times_takes = []\n",
    "    for i in range(0, 5):\n",
    "        start = timer()\n",
    "        main(priors_file, diff_file)\n",
    "        end = timer()\n",
    "        times_takes.append(end - start)\n",
    "\n",
    "    print(times_takes)\n",
    "    print(\"Average Time: \", np.mean(times_takes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:44:06.207812Z",
     "end_time": "2023-04-18T15:44:27.559999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bb = np.zeros((2,3))\n",
    "\n",
    "print(bb[1,2])\n",
    "\n",
    "aa = np.array([2,3,4,5,6,7,8,9,10])\n",
    "print(np.min(aa))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:13:28.312220Z",
     "end_time": "2023-04-18T15:13:28.312414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array([350])\n",
    "b = np.array([110, 100])\n",
    "\n",
    "# Sum all elements of a and b\n",
    "print(np.sum(np.concatenate((a, b))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T15:19:27.256051Z",
     "end_time": "2023-04-18T15:19:27.282180Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
